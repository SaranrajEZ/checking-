{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c830c051-ac75-4374-a525-b70342b1a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba4f5f2-5faf-4bfb-9398-5b82fc4da605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\saranAI\\Deep learning\\facial recognation\\images\\train\"  # Path to your train directory\n",
    "test_dir = r\"C:\\saranAI\\Deep learning\\facial recognation\\images\\test\"    # Path to your test directory\n",
    "model_path = \"facial_recognition_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd65bebe-0053-412b-9c36-a6c0b5268477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize data augmentation for the training set\n",
    "train_aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# For the test set, just rescale the pixel values\n",
    "test_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load the training data\n",
    "train_gen = train_aug.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the test data\n",
    "test_gen = test_aug.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19052cfe-98b0-4878-80ff-d609398b5800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# Load the MobileNetV2 network, ensuring the head FC layers are left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Construct the head of the model that will be placed on top of the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(7, activation=\"softmax\")(headModel)  # Updated for multi-class classification\n",
    "\n",
    "# Place the head FC model on top of the base model\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=1e-4, decay=1e-4 / 20)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be8e0d5-ba39-43d6-8da1-cd4ac146f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      " 69/901 [=>............................] - ETA: 15:41 - loss: 2.1835 - accuracy: 0.1748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_data=test_gen,\n",
    "    validation_steps=len(test_gen),\n",
    "    epochs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb93f1e-6417-43b7-84a5-32b4c7fb5302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
