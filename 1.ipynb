{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c88f8e0-58a9-46b7-bd2b-19a58b4d4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23feda59-b99e-458d-9f88-d106bce63b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv(\"prep.csv\")\n",
    "df = pd.get_dummies(dataset, dtype=int, drop_first=True)\n",
    "\n",
    "# Define input (independent variables) and output (dependent variable)\n",
    "X = df.drop('classification_yes', axis=1)\n",
    "y = df['classification_yes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f12c21f-08fd-475b-acb9-1c3e182339e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca45b5bb-5e2b-43af-a9e4-e5072cebacd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.91575992e+00,  0.00000000e+00,  1.59943471e+00, ...,\n",
       "         5.12501930e-01,  2.04494943e+00, -4.20703162e-01],\n",
       "       [-2.85684653e+00,  0.00000000e+00,  8.37890020e-01, ...,\n",
       "         5.12501930e-01, -4.89009647e-01, -4.20703162e-01],\n",
       "       [-2.79793313e+00,  0.00000000e+00,  7.63453321e-02, ...,\n",
       "         5.12501930e-01, -4.89009647e-01, -4.20703162e-01],\n",
       "       ...,\n",
       "       [-4.18604856e-16, -4.79397659e-01,  1.59943471e+00, ...,\n",
       "        -1.95121217e+00, -4.89009647e-01, -4.20703162e-01],\n",
       "       [-4.18604856e-16,  1.00481749e+00, -6.85199355e-01, ...,\n",
       "         5.12501930e-01, -4.89009647e-01,  2.37697286e+00],\n",
       "       [-4.18604856e-16,  2.62709917e-01, -6.85199355e-01, ...,\n",
       "         5.12501930e-01, -4.89009647e-01, -4.20703162e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b507ad2-fbee-4021-9512-5f3ca80ab982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bgr', 'sc', 'hrmo', 'pcv', 'rc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply RFE with Random Forest\n",
    "rfe_rf = RFE(estimator=RandomForestClassifier(), n_features_to_select=5)\n",
    "X_rf_rfe = rfe_rf.fit_transform(X_scaled, y)\n",
    "selected_features_rf = X.columns[rfe_rf.support_].tolist()\n",
    "selected_features_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d80e060-fee7-4b3d-9073-5ccc6df6d35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Selected Features: ['bgr', 'sc', 'hrmo', 'pcv', 'rc']\n",
      "RandomForest Accuracy: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        39\n",
      "           1       1.00      0.95      0.97        41\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.98      0.98      0.97        80\n",
      "weighted avg       0.98      0.97      0.97        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf_rfe, y, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_rf, y_train_rf)\n",
    "y_pred_rf = rf_model.predict(X_test_rf)\n",
    "print(f\"RandomForest Selected Features: {selected_features_rf}\")\n",
    "print(f\"RandomForest Accuracy: {accuracy_score(y_test_rf, y_pred_rf):.2f}\")\n",
    "print(classification_report(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0f2bf8-7d66-48e1-b4ad-868d7eaad57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTree Selected Features: ['hrmo', 'rc', 'sg_c', 'sg_d', 'htn_yes']\n",
      "DecisionTree Accuracy: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.98      1.00      0.99        41\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.99      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply RFE with Decision Tree\n",
    "rfe_dt = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "X_dt_rfe = rfe_dt.fit_transform(X_scaled, y)\n",
    "selected_features_dt = X.columns[rfe_dt.support_].tolist()\n",
    "X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X_dt_rfe, y, test_size=0.2, random_state=42)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_dt, y_train_dt)\n",
    "y_pred_dt = dt_model.predict(X_test_dt)\n",
    "print(f\"\\nDecisionTree Selected Features: {selected_features_dt}\")\n",
    "print(f\"DecisionTree Accuracy: {accuracy_score(y_test_dt, y_pred_dt):.2f}\")\n",
    "print(classification_report(y_test_dt, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff82642c-f09e-4fc1-9498-3bb1fc843df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Selected Features: ['al', 'sc', 'hrmo', 'pcv', 'sg_d']\n",
      "SVM Accuracy: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        39\n",
      "           1       0.98      0.98      0.98        41\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.97      0.97      0.97        80\n",
      "weighted avg       0.97      0.97      0.97        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply RFE with SVM (using linear kernel)\n",
    "rfe_svm = RFE(estimator=SVC(kernel=\"linear\"), n_features_to_select=5)\n",
    "X_svm_rfe = rfe_svm.fit_transform(X_scaled, y)\n",
    "selected_features_svm = X.columns[rfe_svm.support_].tolist()\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_svm_rfe, y, test_size=0.2, random_state=42)\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train_svm, y_train_svm)\n",
    "y_pred_svm = svm_model.predict(X_test_svm)\n",
    "print(f\"\\nSVM Selected Features: {selected_features_svm}\")\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test_svm, y_pred_svm):.2f}\")\n",
    "print(classification_report(y_test_svm, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71220e0c-32b3-45bd-9da2-6158716574cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Selected Features: ['al', 'hrmo', 'pcv', 'sg_c', 'dm_yes']\n",
      "Logistic Regression Accuracy: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.98      1.00      0.99        41\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.99      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply RFE with Logistic Regression\n",
    "rfe_lr = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
    "X_lr_rfe = rfe_lr.fit_transform(X_scaled, y)\n",
    "selected_features_lr = X.columns[rfe_lr.support_].tolist()\n",
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_lr_rfe, y, test_size=0.2, random_state=42)\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_lr, y_train_lr)\n",
    "y_pred_lr = lr_model.predict(X_test_lr)\n",
    "print(f\"\\nLogistic Regression Selected Features: {selected_features_lr}\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test_lr, y_pred_lr):.2f}\")\n",
    "print(classification_report(y_test_lr, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791b8d40-4380-417f-8f7f-22ea283a5dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Selected Features: ['al', 'hrmo', 'sg_c', 'sg_d', 'htn_yes']\n",
      "XGBoost Accuracy: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        39\n",
      "           1       0.95      1.00      0.98        41\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.98      0.97      0.97        80\n",
      "weighted avg       0.98      0.97      0.97        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply RFE with XGBoost\n",
    "rfe_xgb = RFE(estimator=XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"), n_features_to_select=5)\n",
    "X_xgb_rfe = rfe_xgb.fit_transform(X_scaled, y)\n",
    "selected_features_xgb = X.columns[rfe_xgb.support_].tolist()\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_xgb_rfe, y, test_size=0.2, random_state=42)\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "xgb_model.fit(X_train_xgb, y_train_xgb)\n",
    "y_pred_xgb = xgb_model.predict(X_test_xgb)\n",
    "print(f\"\\nXGBoost Selected Features: {selected_features_xgb}\")\n",
    "print(f\"XGBoost Accuracy: {accuracy_score(y_test_xgb, y_pred_xgb):.2f}\")\n",
    "print(classification_report(y_test_xgb, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6abcf86-3463-4c48-a6c7-af8fb0a81d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost Selected Features: ['al', 'hrmo', 'sg_c', 'sg_d', 'dm_yes']\n",
      "AdaBoost Accuracy: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        39\n",
      "           1       0.95      0.98      0.96        41\n",
      "\n",
      "    accuracy                           0.96        80\n",
      "   macro avg       0.96      0.96      0.96        80\n",
      "weighted avg       0.96      0.96      0.96        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply RFE with AdaBoost using SAMME algorithm to avoid warning\n",
    "rfe_ada = RFE(estimator=AdaBoostClassifier(algorithm=\"SAMME\"), n_features_to_select=5)\n",
    "X_ada_rfe = rfe_ada.fit_transform(X_scaled, y)\n",
    "selected_features_ada = X.columns[rfe_ada.support_].tolist()\n",
    "X_train_ada, X_test_ada, y_train_ada, y_test_ada = train_test_split(X_ada_rfe, y, test_size=0.2, random_state=42)\n",
    "ada_model = AdaBoostClassifier(algorithm=\"SAMME\")\n",
    "ada_model.fit(X_train_ada, y_train_ada)\n",
    "y_pred_ada = ada_model.predict(X_test_ada)\n",
    "print(f\"\\nAdaBoost Selected Features: {selected_features_ada}\")\n",
    "print(f\"AdaBoost Accuracy: {accuracy_score(y_test_ada, y_pred_ada):.2f}\")\n",
    "print(classification_report(y_test_ada, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb47860-55ae-44f1-9820-676141b1e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Decision Tree model, scaler, and selected features\n",
    "with open('ckd_model_dt.pkl', 'wb') as model_file, open('scaler.pkl', 'wb') as scaler_file, open('selected_features_dt.pkl', 'wb') as feature_file:\n",
    "    pickle.dump(dt_model, model_file)\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "    pickle.dump(selected_features_dt, feature_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9fe2c5-0022-40db-a2c6-6e41836da847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the saved Decision Tree model and scaler\n",
    "with open('ckd_model_dt.pkl', 'rb') as model_file, open('scaler.pkl', 'rb') as scaler_file:\n",
    "    dt_model = pickle.load(model_file)\n",
    "    scaler = pickle.load(scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d62f9f8-00e4-4d84-b045-d12eaaf2d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the required features for prediction\n",
    "required_features = ['hrmo', 'rc', 'sg_c', 'sg_d', 'htn_yes']\n",
    "new_data_selected = df[required_features]  # This will include only the specified columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6f19d05-92b1-49c3-82e1-aba144d5f4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hrmo</th>\n",
       "      <th>rc</th>\n",
       "      <th>sg_c</th>\n",
       "      <th>sg_d</th>\n",
       "      <th>htn_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.518156</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.700000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.100000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.800000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>8.700000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>16.300000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hrmo        rc  sg_c  sg_d  htn_yes\n",
       "0    12.518156  4.705597     1     0        0\n",
       "1    10.700000  4.705597     1     0        0\n",
       "2    12.000000  4.705597     0     0        0\n",
       "3     8.100000  4.705597     0     1        0\n",
       "4    11.800000  4.705597     1     0        0\n",
       "..         ...       ...   ...   ...      ...\n",
       "394  12.500000  4.400000     0     0        0\n",
       "395   8.700000  4.705597     1     0        1\n",
       "396   9.100000  3.400000     1     0        1\n",
       "397   8.500000  4.705597     0     0        1\n",
       "398  16.300000  4.900000     0     0        0\n",
       "\n",
       "[399 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecab5612-6f9b-4bd5-9883-d40f884777cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the saved Decision Tree model, scaler, and selected features\n",
    "with open('ckd_model_dt.pkl', 'rb') as model_file, open('scaler.pkl', 'rb') as scaler_file:\n",
    "    dt_model = pickle.load(model_file)\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "# Example new data (replace with actual values)\n",
    "new_data = pd.DataFrame({\n",
    "    'hrmo': [12],   # Replace value_hrmo with the actual value\n",
    "    'rc': [4],       # Replace value_rc with the actual value\n",
    "    'sg_c': [1],   # Replace value_sg_c with the actual value\n",
    "    'sg_d': [0],   # Replace value_sg_d with the actual value\n",
    "    'htn_yes': [0]  # Replace value_htn with the actual value (0 or 1)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aa82cea-3c12-4b4c-86df-2c3f3c9b7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original features used for fitting the scaler (same order)\n",
    "required_features = ['hrmo', 'rc', 'sg_c', 'sg_d', 'htn_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a45f72a5-9026-4296-bb7c-8a6c5ee6ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the required features (ensuring they are in the right order)\n",
    "new_data_selected = new_data[required_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a918b03-b644-42cc-b7c7-a25ef40e096d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- age\n- al\n- ane_yes\n- appet_yes\n- ba_present\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Scale the new data using the fitted scaler\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m new_data_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data_selected\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aimachine\\lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aimachine\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aimachine\\lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aimachine\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- age\n- al\n- ane_yes\n- appet_yes\n- ba_present\n- ...\n"
     ]
    }
   ],
   "source": [
    "#Scale the new data using the fitted scaler\n",
    "new_data_scaled = scaler.transform(new_data_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af77666-f4bb-4b35-af7d-aa91ab9cb79d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
